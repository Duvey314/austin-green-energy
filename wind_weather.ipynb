{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "#import pymongo\n",
    "from path import Path\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import API Key\n",
    "from config import key\n",
    "import config\n",
    "# Documentation:\n",
    "#https://www.worldweatheronline.com/developer/my/analytics.aspx?key_id=222419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set string variables\n",
    "#DEFAULT_DATABASE = 'wind_solar_data' \n",
    "#USERNAME = config.USERNAME\n",
    "#PASSWORD = config.PASSWORD\n",
    "\n",
    "#create connection to database\n",
    "#client = pymongo.MongoClient(f\"mongodb+srv://{USERNAME}:{PASSWORD}@austin-green-energy.pwzpm.mongodb.net/{DEFAULT_DATABASE}?retryWrites=true&w=majority\")\n",
    "#try:\n",
    "#    client.server_info()\n",
    "#    print(\"Mongodb connected\")\n",
    "#except:\n",
    "#    print(\"The Mongodb failed to connect. Check username/password in connection string.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select database\n",
    "#db = client.get_database('wind_solar_data')\n",
    "# select collection\n",
    "#collection = db.wind_data\n",
    "\n",
    "# pull collection into dataframe\n",
    "#wind_df = pd.DataFrame(list(collection.find()))\n",
    "#wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import API Key\n",
    "#from config import key\n",
    "\n",
    "# Documentation:\n",
    "#https://www.worldweatheronline.com/developer/my/analytics.aspx?key_id=222419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a request to the worldweatheronline local history weather API page\n",
    "def makeARequest(location, startDate, endDate, yourAPIKey):\n",
    "    baseURL = \"http://api.worldweatheronline.com/premium/v1/past-weather.ashx\"\n",
    "    timeInterval = \"1\"\n",
    "    outputFormatToReturn = \"json\"\n",
    "\n",
    "    requestURL = f\"{baseURL}?q={location}&date={startDate}&enddate={endDate}&tp={timeInterval}&format={outputFormatToReturn}&key={yourAPIKey}\"\n",
    "    \n",
    "    response = requests.get(requestURL)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        responseJson = response.json()\n",
    "        return responseJson\n",
    "    else:\n",
    "        return print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the wind variables from the responseJson \n",
    "def monthlyHistoricalWeather(firstDayOfMonth, lastDayOfMonth, jsonResponse):\n",
    "    \n",
    "    first = datetime.strptime(firstDayOfMonth, '%Y-%m-%d')\n",
    "    last = datetime.strptime(lastDayOfMonth, '%Y-%m-%d')\n",
    "    numberOfDays = last.day - first.day\n",
    "\n",
    "    HourlyHistoricalWeather = []\n",
    "    \n",
    "    for day in np.arange(0,numberOfDays + 1,1):\n",
    "        for hour in np.arange(0,24,1):\n",
    "            HourlyHistoricalWeather.append({\n",
    "                \"Date\" : jsonResponse[\"data\"][\"weather\"][day][\"date\"],\n",
    "                \"Time\" : jsonResponse[\"data\"][\"weather\"][day][\"hourly\"][hour][\"time\"],\n",
    "                \"WindSpeed_mph\" : jsonResponse[\"data\"][\"weather\"][day][\"hourly\"][hour][\"windspeedMiles\"],\n",
    "                \"WindDirection_degrees\" : jsonResponse[\"data\"][\"weather\"][day][\"hourly\"][hour][\"winddirDegree\"],\n",
    "                \"WindGust_mph\" : jsonResponse[\"data\"][\"weather\"][day][\"hourly\"][hour][\"WindGustMiles\"],\n",
    "                \"Humidity_percent\" : jsonResponse[\"data\"][\"weather\"][day][\"hourly\"][hour][\"humidity\"],\n",
    "                \"Temp_F\" : jsonResponse[\"data\"][\"weather\"][day][\"hourly\"][hour][\"tempF\"]\n",
    "            })\n",
    "\n",
    "    return HourlyHistoricalWeather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Store the variables in a DataFrame\n",
    "def monthlyHistoricalWeatherDF(month):\n",
    "    weatherDataFrame = pd.DataFrame(month)\n",
    "    return weatherDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Latitude and longitude of Hackberry Wind Farm\n",
    "    # https://www.thewindpower.net/windfarm_en_4012_hackberry.php\n",
    "    # Latitude: 32.776111\n",
    "    # Longitude: -99.476444\n",
    "latLong = \"32.776111,-99.476444\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>WindSpeed_mph</th>\n",
       "      <th>WindDirection_degrees</th>\n",
       "      <th>WindGust_mph</th>\n",
       "      <th>Humidity_percent</th>\n",
       "      <th>Temp_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>126</td>\n",
       "      <td>24</td>\n",
       "      <td>73</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>100</td>\n",
       "      <td>13</td>\n",
       "      <td>89</td>\n",
       "      <td>23</td>\n",
       "      <td>74</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>200</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>76</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>300</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>77</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>400</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Time WindSpeed_mph WindDirection_degrees WindGust_mph  \\\n",
       "0  2019-01-01    0            12                   126           24   \n",
       "1  2019-01-01  100            13                    89           23   \n",
       "2  2019-01-01  200            14                    53           23   \n",
       "3  2019-01-01  300            15                    17           22   \n",
       "4  2019-01-01  400            14                    18           21   \n",
       "\n",
       "  Humidity_percent Temp_F  \n",
       "0               73     35  \n",
       "1               74     33  \n",
       "2               76     32  \n",
       "3               77     30  \n",
       "4               77     29  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# January\n",
    "date = \"2019-01-01\"\n",
    "enddate = \"2019-01-31\"\n",
    "\n",
    "responseJson = makeARequest(latLong, date, enddate, key)\n",
    "\n",
    "January = monthlyHistoricalWeather(date, enddate, responseJson)\n",
    "JanuaryDF = monthlyHistoricalWeatherDF(January)\n",
    "JanuaryDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# February\n",
    "date = \"2019-02-01\"\n",
    "enddate = \"2019-02-28\"\n",
    "\n",
    "responseJson = makeARequest(latLong, date, enddate, key)\n",
    "\n",
    "February = monthlyHistoricalWeather(date, enddate, responseJson)\n",
    "FebruaryDF = monthlyHistoricalWeatherDF(February)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# March\n",
    "date = \"2019-03-01\"\n",
    "enddate = \"2019-03-31\"\n",
    "\n",
    "responseJson = makeARequest(latLong, date, enddate, key)\n",
    "\n",
    "March = monthlyHistoricalWeather(date, enddate, responseJson)\n",
    "MarchDF = monthlyHistoricalWeatherDF(March)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# April\n",
    "date = \"2019-04-01\"\n",
    "enddate = \"2019-04-30\"\n",
    "\n",
    "responseJson = makeARequest(latLong, date, enddate, key)\n",
    "\n",
    "April = monthlyHistoricalWeather(date, enddate, responseJson)\n",
    "AprilDF = monthlyHistoricalWeatherDF(April)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# May\n",
    "date = \"2019-05-01\"\n",
    "enddate = \"2019-05-31\"\n",
    "\n",
    "responseJson = makeARequest(latLong, date, enddate, key)\n",
    "\n",
    "May = monthlyHistoricalWeather(date, enddate, responseJson)\n",
    "MayDF = monthlyHistoricalWeatherDF(May)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# June\n",
    "date = \"2019-06-01\"\n",
    "enddate = \"2019-06-30\"\n",
    "\n",
    "responseJson = makeARequest(latLong, date, enddate, key)\n",
    "\n",
    "June = monthlyHistoricalWeather(date, enddate, responseJson)\n",
    "JuneDF = monthlyHistoricalWeatherDF(June)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# July\n",
    "date = \"2019-07-01\"\n",
    "enddate = \"2019-07-31\"\n",
    "\n",
    "responseJson = makeARequest(latLong, date, enddate, key)\n",
    "\n",
    "July = monthlyHistoricalWeather(date, enddate, responseJson)\n",
    "JulyDF = monthlyHistoricalWeatherDF(July)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# August\n",
    "date = \"2019-08-01\"\n",
    "enddate = \"2019-08-31\"\n",
    "\n",
    "responseJson = makeARequest(latLong, date, enddate, key)\n",
    "\n",
    "August = monthlyHistoricalWeather(date, enddate, responseJson)\n",
    "AugustDF = monthlyHistoricalWeatherDF(August)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# September\n",
    "date = \"2019-09-01\"\n",
    "enddate = \"2019-09-30\"\n",
    "\n",
    "responseJson = makeARequest(latLong, date, enddate, key)\n",
    "\n",
    "September = monthlyHistoricalWeather(date, enddate, responseJson)\n",
    "SeptemberDF = monthlyHistoricalWeatherDF(September)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# October\n",
    "date = \"2019-10-01\"\n",
    "enddate = \"2019-10-31\"\n",
    "\n",
    "responseJson = makeARequest(latLong, date, enddate, key)\n",
    "\n",
    "October = monthlyHistoricalWeather(date, enddate, responseJson)\n",
    "OctoberDF = monthlyHistoricalWeatherDF(October)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# November\n",
    "date = \"2019-11-01\"\n",
    "enddate = \"2019-11-30\"\n",
    "\n",
    "responseJson = makeARequest(latLong, date, enddate, key)\n",
    "\n",
    "November = monthlyHistoricalWeather(date, enddate, responseJson)\n",
    "NovemberDF = monthlyHistoricalWeatherDF(November)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# December\n",
    "date = \"2019-12-01\"\n",
    "enddate = \"2019-12-31\"\n",
    "\n",
    "responseJson = makeARequest(latLong, date, enddate, key)\n",
    "\n",
    "December = monthlyHistoricalWeather(date, enddate, responseJson)\n",
    "DecemberDF = monthlyHistoricalWeatherDF(December)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>WindSpeed_mph</th>\n",
       "      <th>WindDirection_degrees</th>\n",
       "      <th>WindGust_mph</th>\n",
       "      <th>Humidity_percent</th>\n",
       "      <th>Temp_F</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>126</td>\n",
       "      <td>24</td>\n",
       "      <td>73</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>100</td>\n",
       "      <td>13</td>\n",
       "      <td>89</td>\n",
       "      <td>23</td>\n",
       "      <td>74</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>200</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>76</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>300</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>77</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>400</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>77</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8755</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1900</td>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>12</td>\n",
       "      <td>39</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8756</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2000</td>\n",
       "      <td>6</td>\n",
       "      <td>176</td>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2100</td>\n",
       "      <td>7</td>\n",
       "      <td>176</td>\n",
       "      <td>14</td>\n",
       "      <td>45</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8758</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2200</td>\n",
       "      <td>7</td>\n",
       "      <td>176</td>\n",
       "      <td>15</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8759</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>2300</td>\n",
       "      <td>7</td>\n",
       "      <td>175</td>\n",
       "      <td>16</td>\n",
       "      <td>48</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8760 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date  Time WindSpeed_mph WindDirection_degrees WindGust_mph  \\\n",
       "0     2019-01-01     0            12                   126           24   \n",
       "1     2019-01-01   100            13                    89           23   \n",
       "2     2019-01-01   200            14                    53           23   \n",
       "3     2019-01-01   300            15                    17           22   \n",
       "4     2019-01-01   400            14                    18           21   \n",
       "...          ...   ...           ...                   ...          ...   \n",
       "8755  2019-12-31  1900             6                   175           12   \n",
       "8756  2019-12-31  2000             6                   176           13   \n",
       "8757  2019-12-31  2100             7                   176           14   \n",
       "8758  2019-12-31  2200             7                   176           15   \n",
       "8759  2019-12-31  2300             7                   175           16   \n",
       "\n",
       "     Humidity_percent Temp_F  \n",
       "0                  73     35  \n",
       "1                  74     33  \n",
       "2                  76     32  \n",
       "3                  77     30  \n",
       "4                  77     29  \n",
       "...               ...    ...  \n",
       "8755               39     49  \n",
       "8756               42     47  \n",
       "8757               45     46  \n",
       "8758               46     46  \n",
       "8759               48     45  \n",
       "\n",
       "[8760 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine each month into a single DataFrame\n",
    "hourlyWeatherDF2019 = JanuaryDF.append([FebruaryDF, MarchDF, AprilDF, MayDF, JuneDF, JulyDF, AugustDF, SeptemberDF, OctoberDF, NovemberDF, DecemberDF]) \n",
    "index = np.arange(0,24*365,1)\n",
    "hourlyWeatherDF2019 = hourlyWeatherDF2019.set_index(index)\n",
    "hourlyWeatherDF2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                     object\n",
       "Time                     object\n",
       "WindSpeed_mph            object\n",
       "WindDirection_degrees    object\n",
       "WindGust_mph             object\n",
       "Humidity_percent         object\n",
       "Temp_F                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourlyWeatherDF2019.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyWeatherDF2019.to_csv(r'Output/hourlyWeatherDF2019.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing ETL on Wind Data at Hackberry Wind Farm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cleaningDataFrame_datetime(df):\n",
    "#     df['Date'] = pd.to_datetime(df['Date'])\n",
    "#     df['Time'] = df['Time'].astype(int)\n",
    "#     df['Time'] = (df['Time']/100).astype(int)\n",
    "#     df['Time'] = df['Time'].astype('timedelta64[h]')\n",
    "#     df['Time'] = df['Time'] - pd.to_timedelta(df['Time'].dt.days, unit='d')\n",
    "#     df['Date_Time'] = df['Date'] + df['Time']\n",
    "#     df = df.drop(['Time', 'Date'], 1)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyWeatherDF2019['Date'] = pd.to_datetime(hourlyWeatherDF2019['Date'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyWeatherDF2019.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyWeatherDF2019['Time'] = hourlyWeatherDF2019['Time'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyWeatherDF2019['Time'] = hourlyWeatherDF2019['Time']/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyWeatherDF2019['Time'] = hourlyWeatherDF2019['Time'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyWeatherDF2019['time'] =pd.to_timedelta(hourlyWeatherDF2019['Time'], unit='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-7ec325fc444a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Creating new column called 'hour' in timedelta format without date\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhourlyWeatherDF2019\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhourlyWeatherDF2019\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_timedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhourlyWeatherDF2019\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'd'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5268\u001b[0m             \u001b[1;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5269\u001b[0m         ):\n\u001b[1;32m-> 5270\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5271\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, cls)\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0maccessor_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m         \u001b[1;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;31m# http://www.pydanny.com/cached-property.html\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\accessors.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, data)\u001b[0m\n\u001b[0;32m    336\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mDatetimeProperties\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Can only use .dt accessor with datetimelike values\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "# Creating new column called 'hour' in timedelta format without date\n",
    "hourlyWeatherDF2019['Time'] = hourlyWeatherDF2019['Time'] - pd.to_timedelta(hourlyWeatherDF2019['Time'].dt.days, unit='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hourlyWeatherDF2019.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Date and hour to a single column as they are in datetime and timedelta formats\n",
    "#hourlyWeatherDF2019['time_combined'] = hourlyWeatherDF2019['Date'] + hourlyWeatherDF2019['time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the original 'Time' column from \n",
    "#hourlyWeatherDF2019 = hourlyWeatherDF2019.drop(['Time', 'Date', 'time'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming time column name.\n",
    "hourlyWeatherDF2019.rename(columns = {'time_combined':'time'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-arranging the column headers\n",
    "hourlyWeatherDF2019 = hourlyWeatherDF2019[['time', 'WindSpeed_mph', 'WindDirection_degrees', 'WindGust_mph', 'Temp_F', 'Humidity_percent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyWeatherDF2019['WindSpeed_mph'] = hourlyWeatherDF2019['WindSpeed_mph'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyWeatherDF2019['WindDirection_degrees'] = hourlyWeatherDF2019['WindDirection_degrees'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyWeatherDF2019['WindGust_mph'] = hourlyWeatherDF2019['WindGust_mph'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyWeatherDF2019['Humidity_percent'] = hourlyWeatherDF2019['Humidity_percent'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourlyWeatherDF2019['Temp_F'] = hourlyWeatherDF2019['Temp_F'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2019Clean = hourlyWeatherDF2019.drop(hourlyWeatherDF2019.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2019Clean.to_csv(r'Output/weather_wind.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather2019Clean.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing and Performing ETL on Hackberry Wind Energy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"Resources/Hackberry_Generation.csv\"\n",
    "Hackberry_df = pd.read_csv(data)\n",
    "Hackberry_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hackberry_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping Unit Column\n",
    "Hackberry_df = Hackberry_df.drop('Unit', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming column name from 'Hour Ending' to 'Hour'\n",
    "Hackberry_df.rename(columns = {'Hour Ending':'Hour'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting Date to datetime\n",
    "Hackberry_df['Date'] = pd.to_datetime(Hackberry_df['Date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data type\n",
    "Hackberry_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the last two characters from the hour column as the times are hourly\n",
    "Hackberry_df['Hour'] = Hackberry_df['Hour'].astype(str).str[:-2].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Hour data type\n",
    "Hackberry_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hackberry_df['hour'] =pd.to_timedelta(Hackberry_df['Hour'], unit='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new column called 'hour' in timedelta format without date\n",
    "Hackberry_df['hour'] = Hackberry_df['hour'] - pd.to_timedelta(Hackberry_df['hour'].dt.days, unit='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the original 'Hour' column\n",
    "Hackberry_df = Hackberry_df.drop('Hour', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-arranging the column headers\n",
    "Hackberry_df = Hackberry_df[[\"Date\", \"hour\", \"MWH\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hackberry_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Date and hour to a single column as they are in datetime and timedelta formats\n",
    "Hackberry_df['time'] = Hackberry_df['Date'] + Hackberry_df['hour']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-arranging the column headers and removing the Date and hour columns\n",
    "Hackberry_df = Hackberry_df[[\"time\", \"MWH\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hackberry_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hackberry_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing rows to include only 2019 year data to include same time range as wind data\n",
    "Hackberry2019 = Hackberry_df.drop(Hackberry_df.index[8759:13871])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hackberry2019.to_csv(r'Output/Hackberry_MHW.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging Hackberry Energy Data with Wind Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberryWindMWH = pd.merge(weather2019Clean, Hackberry2019, on='time', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberryWindMWH =hackberryWindMWH.drop(hackberryWindMWH.index[8760])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberryWindMWH.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberryWindMWH.to_csv(r'Output/Hackberry_Wind_MHW.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberryWindMWH.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 72 turbines in Hackberry Farm.\n",
    "hackberryWindMWH['MWH'] = hackberryWindMWH['MWH']/72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberryWindMWH.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberry = hackberryWindMWH.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hackberry[\"WindSpeed_mph\"] = hackberry[\"WindSpeed_mph\"].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hackberry' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-b54760bbcb7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visually inspect the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhackberry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWindSpeed_mph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhackberry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMWH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Wind Speed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'MHW'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hackberry' is not defined"
     ]
    }
   ],
   "source": [
    "# Visually inspect the data\n",
    "plt.scatter(hackberry.WindSpeed_mph, hackberry.MWH)\n",
    "plt.xlabel('Wind Speed')\n",
    "plt.ylabel('MHW')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  It can be concluded that linear regression on wind speed alone does not track the power generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hackberry' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-1bb5ce448ee8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save csv file to be used later without going through the ETL process.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhackberry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'Output/hackberry_encoded.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mhackberry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'Resources/hackberry_encoded.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hackberry' is not defined"
     ]
    }
   ],
   "source": [
    "# Save csv file to be used later without going through the ETL process.\n",
    "hackberry.to_csv(r'Output/hackberry_encoded.csv', index = False)\n",
    "hackberry.to_csv(r'Resources/hackberry_encoded.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the csv file from resources\n",
    "data = \"Resources/hackberry_encoded.csv\"\n",
    "hackberry_encoded = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberryEncoded = hackberry_encoded.drop([\"time\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberryEncoded[\"WindSpeed_mph\"] = hackberryEncoded[\"WindSpeed_mph\"].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberryEncoded[\"WindDirection_degrees\"] = hackberryEncoded[\"WindDirection_degrees\"].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberryEncoded[\"Temp_F\"] = hackberryEncoded[\"Temp_F\"].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberryEncoded[\"Humidity_percent\"] = hackberryEncoded[\"Humidity_percent\"].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberryEncoded[\"WindGust_mph\"] = hackberryEncoded[\"WindGust_mph\"].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberryEncoded[\"MWH\"] = hackberryEncoded[\"MWH\"].round(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the scaler instance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "hackberry_scaled = data_scaler.fit_transform(hackberryEncoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.3608004 , -1.05022902,  0.74188853, -1.84416382,  0.9587771 ,\n",
       "         1.76060903],\n",
       "       [ 0.56803347, -1.53116107,  0.74188853, -1.89917018,  1.06779963,\n",
       "         0.40636576],\n",
       "       [ 0.77526654, -2.01209313,  0.60454765, -2.00918289,  1.1223109 ,\n",
       "         0.40636576],\n",
       "       [ 0.56803347, -1.99873391,  0.46720677, -2.06418925,  1.1223109 ,\n",
       "         0.40636576],\n",
       "       [ 0.56803347, -1.98537468,  0.32986589, -2.11919561,  1.06779963,\n",
       "         0.40636576]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hackberry_scaled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1196037626729142e-16\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(hackberry_scaled[:,0]))\n",
    "print(np.std(hackberry_scaled[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WindSpeed_mph</th>\n",
       "      <th>WindDirection_degrees</th>\n",
       "      <th>WindGust_mph</th>\n",
       "      <th>Temp_F</th>\n",
       "      <th>Humidity_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>89</td>\n",
       "      <td>23</td>\n",
       "      <td>33</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>30</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   WindSpeed_mph  WindDirection_degrees  WindGust_mph  Temp_F  \\\n",
       "0             13                     89            23      33   \n",
       "1             14                     53            23      32   \n",
       "2             15                     17            22      30   \n",
       "3             14                     18            21      29   \n",
       "4             14                     19            20      28   \n",
       "\n",
       "   Humidity_percent  \n",
       "0                74  \n",
       "1                76  \n",
       "2                77  \n",
       "3                77  \n",
       "4                76  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the features set.\n",
    "X = hackberryEncoded.copy()\n",
    "X = X.drop(\"MWH\", axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the target set.\n",
    "y = hackberryEncoded[\"MWH\"].ravel()\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "#from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with sklearn\n",
    "lm = linear_model.LinearRegression()\n",
    "model = lm.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3423667651596264"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Return the coefficient of determination R^2 of the prediction\n",
    "#The coefficient R^2 is defined as (1 - u/v), where u is the residual sum of squares ((y_true - y_pred) ** 2).sum() and \n",
    "#v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum().\n",
    "#The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse).\n",
    "#A constant model that always predicts the expected value of y,\n",
    "#disregarding the input features, would get a R^2 score of 0.0.\n",
    "\n",
    "lm.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.95710852e-03,  5.44010624e-04,  6.16989085e-02,  5.67109374e-05,\n",
       "        2.84278391e-03])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5403324965151426"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Balanced Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 3089, 1: 2421, 2: 1058})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "brfc = BalancedRandomForestClassifier(n_estimators=100, random_state=1)\n",
    "#split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)\n",
    "brfc.fit(X_train, y_train)\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7292707753306864"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = brfc.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[764, 156,  87],\n",
       "       [112, 475, 186],\n",
       "       [ 10,  66, 334]], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.86      0.76      0.90      0.81      0.82      0.67      1007\n",
      "          1       0.68      0.61      0.84      0.65      0.72      0.51       773\n",
      "          2       0.55      0.81      0.85      0.66      0.83      0.69       410\n",
      "\n",
      "avg / total       0.74      0.72      0.87      0.72      0.79      0.62      2190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.3001313240231106, 'WindGust_mph'),\n",
       " (0.2164485679681333, 'WindDirection_degrees'),\n",
       " (0.17125360268903886, 'Temp_F'),\n",
       " (0.17047127842672988, 'Humidity_percent'),\n",
       " (0.1416952268929874, 'WindSpeed_mph')]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "importances = brfc.feature_importances_\n",
    "sorted(zip(brfc.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a StandardScaler instance.\n",
    "scaler = StandardScaler()\n",
    "# Fitting the Standard Scaler with the training data.\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling the data.\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier.\n",
    "rf_model = RandomForestClassifier(n_estimators=128, random_state=78) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model\n",
    "rf_model = rf_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data.\n",
    "predictions = rf_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the accuracy score.\n",
    "acc_score = accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7488584474885844\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy Score : {acc_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14092194, 0.2281864 , 0.27265895, 0.17730254, 0.18093017])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate feature importance in the Random Forest model.\n",
    "importances = rf_model.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2726589497161064, 'WindGust_mph'),\n",
       " (0.22818639974566826, 'WindDirection_degrees'),\n",
       " (0.1809301724870095, 'Humidity_percent'),\n",
       " (0.17730254227777692, 'Temp_F'),\n",
       " (0.140921935773439, 'WindSpeed_mph')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can sort the features by their importance.\n",
    "sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83      1007\n",
      "           1       0.67      0.70      0.68       773\n",
      "           2       0.71      0.63      0.67       410\n",
      "\n",
      "    accuracy                           0.75      2190\n",
      "   macro avg       0.74      0.72      0.73      2190\n",
      "weighted avg       0.75      0.75      0.75      2190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                   n_estimators=400)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Forest to be composed of trees with a single decision node and two leaves. 400 estimators to specify the total number of trees in forest\n",
    "classifier = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),n_estimators=400)\n",
    "classifier.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[749, 204,  52],\n",
       "       [200, 525,  99],\n",
       "       [ 32, 126, 203]], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6764101393012103"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-49980cf1146b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Define the model - deep neural net\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnumber_input_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mhidden_nodes_layer1\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnumber_input_features\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhidden_nodes_layer2\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnumber_input_features\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Define the model - deep neural net\n",
    "number_input_features = 3\n",
    "hidden_nodes_layer1 =  number_input_features*3\n",
    "hidden_nodes_layer2 =  number_input_features*3\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"linear\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"linear\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(optimizer=\"sgd\", loss=tf.keras.losses.MeanSquaredError(), metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example from https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "seed = 1\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=3, activation='linear'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "# estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=100, verbose=False)\n",
    "# kfold = KFold(n_splits=10, random_state=seed)\n",
    "# results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "# print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "\n",
    "# estimator.fit(X, y)\n",
    "# prediction = estimator.predict(X)\n",
    "# accuracy_score(y, prediction)\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model)\n",
    "estimator.fit(X_train_scaled, y_train, nb_epoch=100, batch_size=100, verbose=False, shuffle=False)\n",
    "prediction = estimator.predict(X_test_scaled)\n",
    "r2_score(y_test, prediction)\n",
    "\n",
    "# model = baseline_model()\n",
    "# model.fit(X, y, nb_epoch=100, batch_size=100, verbose=False, shuffle=False)\n",
    "# prediction = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nbviewer.jupyter.org/github/srnghn/ml_example_notebooks/blob/master/Predicting%20Wine%20Types%20with%20Neural%20Networks.ipynb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "accuracy_score(y_train, model.predict(X_train_scaled))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
