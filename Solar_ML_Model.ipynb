{
 "cells": [
  {
   "source": [
    "# Wind Machine Learning Model\n",
    "This notebook creates a machine learning model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Imports\n",
    "from path import Path\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Database Connection\n",
    "import config\n",
    "import pymongo\n",
    "\n",
    "# datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, balanced_accuracy_score\n",
    "\n",
    "# don't show warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "source": [
    "# Import Data from Database"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mongodb connected\n"
     ]
    }
   ],
   "source": [
    "# set string variables\n",
    "DEFAULT_DATABASE = 'wind_solar_data' \n",
    "USERNAME = config.USERNAME\n",
    "PASSWORD = config.PASSWORD\n",
    "\n",
    "#create connection to database\n",
    "client = pymongo.MongoClient(f\"mongodb+srv://{USERNAME}:{PASSWORD}@austin-green-energy.pwzpm.mongodb.net/{DEFAULT_DATABASE}?retryWrites=true&w=majority\")\n",
    "try:\n",
    "    client.server_info()\n",
    "    print(\"Mongodb connected\")\n",
    "except:\n",
    "    print(\"The Mongodb failed to connect. Check username/password in connection string.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                            _id        Date                       Time  \\\n",
       "0      5f946c27c64c67a0641fe930  2019-01-01  0 days 00:00:00.000000000   \n",
       "1      5f946c27c64c67a0641fe931  2019-01-01  0 days 01:00:00.000000000   \n",
       "2      5f946c27c64c67a0641fe932  2019-01-01  0 days 02:00:00.000000000   \n",
       "3      5f946c27c64c67a0641fe933  2019-01-01  0 days 03:00:00.000000000   \n",
       "4      5f946c27c64c67a0641fe934  2019-01-01  0 days 04:00:00.000000000   \n",
       "...                         ...         ...                        ...   \n",
       "13868  5f946c27c64c67a064201f5c  2020-07-31  0 days 19:00:00.000000000   \n",
       "13869  5f946c27c64c67a064201f5d  2020-07-31  0 days 20:00:00.000000000   \n",
       "13870  5f946c27c64c67a064201f5e  2020-07-31  0 days 21:00:00.000000000   \n",
       "13871  5f946c27c64c67a064201f5f  2020-07-31  0 days 22:00:00.000000000   \n",
       "13872  5f946c27c64c67a064201f60  2020-07-31  0 days 23:00:00.000000000   \n",
       "\n",
       "       temperature(F)  cloudcover(%)  uvIndex weatherDescription  humidity  \\\n",
       "0                  43              0        1              Clear        88   \n",
       "1                  43              0        1              Clear        88   \n",
       "2                  43              0        1              Clear        88   \n",
       "3                  43              0        1              Clear        88   \n",
       "4                  43              0        1              Clear        88   \n",
       "...               ...            ...      ...                ...       ...   \n",
       "13868              79             73        1      Partly cloudy        89   \n",
       "13869              79             73        1      Partly cloudy        89   \n",
       "13870              79             73        1      Partly cloudy        89   \n",
       "13871              79             73        1      Partly cloudy        89   \n",
       "13872              79             73        1      Partly cloudy        89   \n",
       "\n",
       "                 Date_Time  MWH  \n",
       "0      2019-01-01 00:00:00  0.0  \n",
       "1      2019-01-01 01:00:00  0.0  \n",
       "2      2019-01-01 02:00:00  0.0  \n",
       "3      2019-01-01 03:00:00  0.0  \n",
       "4      2019-01-01 04:00:00  0.0  \n",
       "...                    ...  ...  \n",
       "13868  2020-07-31 19:00:00  0.0  \n",
       "13869  2020-07-31 20:00:00  0.0  \n",
       "13870  2020-07-31 21:00:00  0.0  \n",
       "13871  2020-07-31 22:00:00  0.0  \n",
       "13872  2020-07-31 23:00:00  0.0  \n",
       "\n",
       "[13873 rows x 10 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>_id</th>\n      <th>Date</th>\n      <th>Time</th>\n      <th>temperature(F)</th>\n      <th>cloudcover(%)</th>\n      <th>uvIndex</th>\n      <th>weatherDescription</th>\n      <th>humidity</th>\n      <th>Date_Time</th>\n      <th>MWH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5f946c27c64c67a0641fe930</td>\n      <td>2019-01-01</td>\n      <td>0 days 00:00:00.000000000</td>\n      <td>43</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Clear</td>\n      <td>88</td>\n      <td>2019-01-01 00:00:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5f946c27c64c67a0641fe931</td>\n      <td>2019-01-01</td>\n      <td>0 days 01:00:00.000000000</td>\n      <td>43</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Clear</td>\n      <td>88</td>\n      <td>2019-01-01 01:00:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5f946c27c64c67a0641fe932</td>\n      <td>2019-01-01</td>\n      <td>0 days 02:00:00.000000000</td>\n      <td>43</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Clear</td>\n      <td>88</td>\n      <td>2019-01-01 02:00:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5f946c27c64c67a0641fe933</td>\n      <td>2019-01-01</td>\n      <td>0 days 03:00:00.000000000</td>\n      <td>43</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Clear</td>\n      <td>88</td>\n      <td>2019-01-01 03:00:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5f946c27c64c67a0641fe934</td>\n      <td>2019-01-01</td>\n      <td>0 days 04:00:00.000000000</td>\n      <td>43</td>\n      <td>0</td>\n      <td>1</td>\n      <td>Clear</td>\n      <td>88</td>\n      <td>2019-01-01 04:00:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13868</th>\n      <td>5f946c27c64c67a064201f5c</td>\n      <td>2020-07-31</td>\n      <td>0 days 19:00:00.000000000</td>\n      <td>79</td>\n      <td>73</td>\n      <td>1</td>\n      <td>Partly cloudy</td>\n      <td>89</td>\n      <td>2020-07-31 19:00:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13869</th>\n      <td>5f946c27c64c67a064201f5d</td>\n      <td>2020-07-31</td>\n      <td>0 days 20:00:00.000000000</td>\n      <td>79</td>\n      <td>73</td>\n      <td>1</td>\n      <td>Partly cloudy</td>\n      <td>89</td>\n      <td>2020-07-31 20:00:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13870</th>\n      <td>5f946c27c64c67a064201f5e</td>\n      <td>2020-07-31</td>\n      <td>0 days 21:00:00.000000000</td>\n      <td>79</td>\n      <td>73</td>\n      <td>1</td>\n      <td>Partly cloudy</td>\n      <td>89</td>\n      <td>2020-07-31 21:00:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13871</th>\n      <td>5f946c27c64c67a064201f5f</td>\n      <td>2020-07-31</td>\n      <td>0 days 22:00:00.000000000</td>\n      <td>79</td>\n      <td>73</td>\n      <td>1</td>\n      <td>Partly cloudy</td>\n      <td>89</td>\n      <td>2020-07-31 22:00:00</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>13872</th>\n      <td>5f946c27c64c67a064201f60</td>\n      <td>2020-07-31</td>\n      <td>0 days 23:00:00.000000000</td>\n      <td>79</td>\n      <td>73</td>\n      <td>1</td>\n      <td>Partly cloudy</td>\n      <td>89</td>\n      <td>2020-07-31 23:00:00</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>13873 rows Ã— 10 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# select database\n",
    "db = client.get_database('wind_solar_data')\n",
    "# select collection\n",
    "collection = db.solar_data\n",
    "\n",
    "# pull collection into dataframe\n",
    "solar_df = pd.DataFrame(list(collection.find()))\n",
    "solar_df"
   ]
  },
  {
   "source": [
    "### Drop Columns\n",
    "The first cleaning is to drop the columns we dont't need. We'll be dropping the _id column because this is an artifact of the Mongodb storage and isn't a feature of the dataset. The time column will be dropped because there is not a linear relationship between time and wind power. The winddirection compas is dropped because this data is less granular than the winddirection degrees."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop uneeded columns\n",
    "wind_clean_df = wind_df.drop(['_id', \"WindDirection_compass\"], axis=1)"
   ]
  },
  {
   "source": [
    "### Type Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "time                     0\n",
       "WindSpeed_mph            0\n",
       "WindDirection_degrees    0\n",
       "WindGust_mph             0\n",
       "MWH                      0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "wind_clean_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any NaN values\n",
    "wind_clean_df = wind_clean_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "time                     datetime64[ns]\n",
       "WindSpeed_mph                     int32\n",
       "WindDirection_degrees             int32\n",
       "WindGust_mph                      int32\n",
       "MWH                               int32\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "wind_clean_df[\"WindSpeed_mph\"] = wind_clean_df[\"WindSpeed_mph\"].round(0).astype(int)\n",
    "wind_clean_df[\"WindDirection_degrees\"] = wind_clean_df[\"WindDirection_degrees\"].round(0).astype(int)\n",
    "wind_clean_df[\"WindGust_mph\"] = wind_clean_df[\"WindGust_mph\"].round(0).astype(int)\n",
    "wind_clean_df['time'] = pd.to_datetime(wind_clean_df['time'])\n",
    "wind_clean_df[\"MWH\"] = wind_clean_df[\"MWH\"].round(0).astype(int)\n",
    "wind_clean_df.dtypes"
   ]
  },
  {
   "source": [
    "# ML Models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "Date time not supported in linear Regression."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Split Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features set.\n",
    "#wind_clean_df = wind_clean_df.reset_index()\n",
    "X = wind_clean_df.drop([\"MWH\",'time'], axis=1)\n",
    "y = wind_clean_df[\"MWH\"].ravel()\n",
    "\n",
    "#split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a StandardScaler instance.\n",
    "scaler = StandardScaler()\n",
    "# Fitting the Standard Scaler with the training data.\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scaling the data.\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# Train\n",
    "\n",
    "regr = LinearRegression()\n",
    "regr.fit(X_train_scaled,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 250.91702586,  708.69483708,  754.48646983, ...,  577.67519832,\n",
       "       1124.06354202, 1293.8023135 ])"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "# test\n",
    "y_pred = regr.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "38.07819369662388 %\nR^2 Value:0.38078193696623874\n"
     ]
    }
   ],
   "source": [
    "accuracy = regr.score(X_test_scaled,y_test)\n",
    "print(accuracy*100,'%')\n",
    "print(f\"R^2 Value:{regr.score(X_test_scaled,y_test)}\")\n"
   ]
  },
  {
   "source": [
    "## Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "6568/6568 [==============================] - 0s 28us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 2/50\n",
      "6568/6568 [==============================] - 0s 20us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 3/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 4/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 5/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 6/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 7/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 8/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 9/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 10/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 11/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 12/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 13/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 14/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 15/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 16/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 17/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 18/50\n",
      "6568/6568 [==============================] - 0s 20us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 19/50\n",
      "6568/6568 [==============================] - 0s 20us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 20/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 21/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 22/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 23/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 24/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 25/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 26/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 27/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 28/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 29/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 30/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 31/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 32/50\n",
      "6568/6568 [==============================] - 0s 20us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 33/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 34/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 35/50\n",
      "6568/6568 [==============================] - 0s 22us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 36/50\n",
      "6568/6568 [==============================] - 0s 20us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 37/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 38/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 39/50\n",
      "6568/6568 [==============================] - 0s 22us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 40/50\n",
      "6568/6568 [==============================] - 0s 18us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 41/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 42/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 43/50\n",
      "6568/6568 [==============================] - 0s 21us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 44/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 45/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 46/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 47/50\n",
      "6568/6568 [==============================] - 0s 21us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 48/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 49/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "Epoch 50/50\n",
      "6568/6568 [==============================] - 0s 19us/sample - loss: nan - acc: 0.0606\n",
      "2190/2190 - 0s - loss: nan - acc: 0.0689\n",
      "Loss: nan, Accuracy: 0.06894977390766144\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Define the model - deep neural net\n",
    "number_input_features = 3\n",
    "hidden_nodes_layer1 =  number_input_features*3\n",
    "hidden_nodes_layer2 =  number_input_features*3\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(\n",
    "    tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"linear\")\n",
    ")\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"linear\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"linear\"))\n",
    "\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(optimizer=\"sgd\", loss=tf.keras.losses.MeanSquaredError(), metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'KerasRegressor' object has no attribute 'evaluate'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-e62965086dc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m#r2_score(y_test, prediction)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mmodel_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Loss: {model_loss}, Accuracy: {model_accuracy}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KerasRegressor' object has no attribute 'evaluate'"
     ]
    }
   ],
   "source": [
    "# Example from https://machinelearningmastery.com/regression-tutorial-keras-deep-learning-library-python/\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "seed = 1\n",
    "\n",
    "def baseline_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(10, input_dim=3, activation='linear'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model\n",
    "\n",
    "\n",
    "# estimator = KerasRegressor(build_fn=baseline_model, nb_epoch=100, batch_size=100, verbose=False)\n",
    "# kfold = KFold(n_splits=10, random_state=seed)\n",
    "# results = cross_val_score(estimator, X, y, cv=kfold)\n",
    "# print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))\n",
    "\n",
    "# estimator.fit(X, y)\n",
    "# prediction = estimator.predict(X)\n",
    "# accuracy_score(y, prediction)\n",
    "\n",
    "estimator = KerasRegressor(build_fn=baseline_model)\n",
    "estimator.fit(X_train_scaled, y_train, nb_epoch=100, batch_size=100, verbose=False, shuffle=False)\n",
    "prediction = estimator.predict(X_test_scaled)\n",
    "r2_score(y_test, prediction)\n",
    "\n",
    "# model = baseline_model()\n",
    "# model.fit(X, y, nb_epoch=100, batch_size=100, verbose=False, shuffle=False)\n",
    "# prediction = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.09043848964677223"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "# https://nbviewer.jupyter.org/github/srnghn/ml_example_notebooks/blob/master/Predicting%20Wine%20Types%20with%20Neural%20Networks.ipynb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "accuracy_score(y_train, model.predict(X_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([28, 49, 15, ..., 86, 28, 11])"
      ]
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 14,   1,   0, ..., 115,  24,  14])"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "model.predict(X_train_scaled)"
   ]
  },
  {
   "source": [
    "## Random Forrest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample the training data with the RandomOversampler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "brfc = BalancedRandomForestClassifier(n_estimators=100, random_state=1)\n",
    "brfc.fit(X_train, y_train)\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated the balanced accuracy score\n",
    "y_pred = brfc.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the imbalanced classification report\n",
    "print(classification_report_imbalanced(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "importances = brfc.feature_importances_\n",
    "sorted(zip(brfc.feature_importances_, X.columns), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.7 64-bit ('PythonData': conda)",
   "display_name": "Python 3.7.7 64-bit ('PythonData': conda)",
   "metadata": {
    "interpreter": {
     "hash": "afc7c4a812fa55c0db985e1c504d2cd5747faf27fd01c3486b2fd8146566cace"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}